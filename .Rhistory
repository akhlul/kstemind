untuk memperkaya diri sendiri ataupun golongan."
cat(sapply(tokenize_indonesian(teks), stemmer$stem, USE.NAMES = F))
teks
library(reprex)
reprex()
reprex()
# melakukan stemming pada sebuah kata
stemmer$stem("pertikaian")
roxygen2::roxygenize()
roxygen2::roxygenize()
library(kstemind)
tokenize_indonesian(teks)
roxygen2::roxygenize()
library(kstemind)
tokenize_indonesian(teks)
stopwords_removal(tokenize_indonesian(teks))
stopwords_removal(tokenize_indonesian(teks, do_clean = T))
roxygen2::roxygenise()
library(kstemind)
library(kstemind)
library(kstemind)
library(kstemind)
library(kstemind)
library(kstemind)
stemmer <- stemmer_cs$new()
stemmer$stem("memakan")
stemmer$stem_word("memakan")
stemmer$stem_word("dimakan")
stemmer <- stemmer_ecs$new()
stemmer$stem_word("memakan")
stemmer$stem_word("dimakan")
library(kstemind)
stemmer <- stemmer_ecs$new()
stemmer$stem_word("dimakan")
stemmer$stem_word("balas-balas")
library(kstemind)
stemmer <- stemmer_ecs$new()
stemmer$stem_word("dimakan")
rules <- "\\bbe(.*)lah\\b|\\bbe(.*)an\\b|\\bme(.*)i\\b|\\bdi(.*)i\\b|\\bpe(.*)i\\b|\\bter(.*)i\\b"
str_detect("dimakan", rules)
stringr::str_detect("dimakan", rules)
library(kstemind)
stemmer <- stemmer_ecs$new()
stemmer$stem_word("dimakan")
library(kstemind)
stemmer <- stemmer_ecs$new()
stemmer$stem_word("dimakan")
stemmer$stem_word("diselesaikan")
library(kstemind)
stemmer <- stemmer_ecs$new()
stemmer$stem_word("dimakan")
stemmer$stem_word("diselesaikan")
stemmer$stem_word("melerai")
library(kstemind)
split_by_sentence <- function (text) {
# split based on periods, exclams or question marks
result <- unlist (strsplit (text, split = "[\\.!?]+"))
# do not return empty strings
result <- stri_trim_both (result)
result <- result [nchar (result) > 0]
# ensure that something is always returned
if (length (result) == 0)
result <- ""
return (result)
}
word <- "One of the most common things we might want to do is read in, clean, and "tokenize" (split into individual words) a raw input text file. There are a number of packages that make this quite easy to do in R (I recommend and use quanteda)."
word <- "One of the most common things we might want to do is read in, clean, and \"tokenize\" (split into individual words) a raw input text file. There are a number of packages that make this quite easy to do in R (I recommend and use quanteda)."
split_by_sentence(word)
library(stringr)
str_split(word, "[\\.!?]+")
b <- str_split(word, "[\\.!?]+")
str_trim(b[[1]], "both")
str_trim(b, "both")
#' Chunking Tokens of Word
#'
#' @param text long string
#' @param chunk_size (default = 100)
#' @param text_id (default = "teks")
#'
#' @return list of chunked tokenized text
#' @import stringr textclean htm2txt
#' @export
chunk_text <- function(text, by_size = F, chunk_size = 100) {
# chunks <- split(tokenized_text, ceiling(seq_along(tokenized_text)/chunk_size))
#
# num_chars <- str_length(length(chunks))
# chunk_ids <- str_pad(seq(length(chunks)), num_chars, side = "left", pad = "0")
# names(chunks) <- str_c(text_id, chunk_ids, sep = "_")
chunks <- unlist(str_split(text, "[\\.!?]+"))
chunks <- str_trim(chunks, "both")
return(chunks)
}
chuck_text(word)
chunk_text(word)
#' Chunking Tokens of Word
#'
#' @param text long string
#' @param chunk_size (default = 100)
#' @param text_id (default = "teks")
#'
#' @return list of chunked tokenized text
#' @import stringr textclean htm2txt
#' @export
chunk_text <- function(text, by_size = F, chunk_size = 100) {
# chunks <- split(tokenized_text, ceiling(seq_along(tokenized_text)/chunk_size))
#
# num_chars <- str_length(length(chunks))
# chunk_ids <- str_pad(seq(length(chunks)), num_chars, side = "left", pad = "0")
# names(chunks) <- str_c(text_id, chunk_ids, sep = "_")
chunks <- unlist(str_split(text, "[\\.!?]+"))
chunks <- str_trim(chunks, "both")
chunks <- chunks[nchar(chunks) > 0]
return(chunks)
}
chunk_text(word)
#' Chunking Tokens of Word
#'
#' @param text long string
#' @param chunk_size (default = 100)
#' @param text_id (default = "teks")
#'
#' @return list of chunked tokenized text
#' @import stringr textclean htm2txt
#' @export
chunk_text <- function(text, by_size = F, chunk_size = 100) {
if(by_size){
tokenized_text <- tokenize_indonesian(text)
chunks <- split(tokenized_text, ceiling(seq_along(tokenized_text)/chunk_size))
num_chars <- str_length(length(chunks))
chunk_ids <- str_pad(seq(length(chunks)), num_chars, side = "left", pad = "0")
names(chunks) <- str_c(text_id, chunk_ids, sep = "_")
return(chunks)
} else {
chunks <- unlist(str_split(text, "[\\.!?]+"))
chunks <- str_trim(chunks, "both")
chunks <- chunks[nchar(chunks) > 0]
return(chunks)
}
}
chunk_text(word, T)
library(kstemind)
chunk_text(word, T)
#' Chunking Tokens of Word
#'
#' @param text long string
#' @param chunk_size (default = 100)
#' @param text_id (default = "teks")
#'
#' @return list of chunked tokenized text
#' @import stringr textclean htm2txt
#' @export
chunk_text <- function(text, by_size = F, chunk_size = 100) {
if(by_size){
tokenized_text <- tokenize_indonesian(text)
chunks <- split(tokenized_text, ceiling(seq_along(tokenized_text)/chunk_size))
num_chars <- str_length(length(chunks))
chunk_ids <- str_pad(seq(length(chunks)), num_chars, side = "left", pad = "0")
names(chunks) <- str_c("id_", chunk_ids, sep = "_")
return(chunks)
} else {
chunks <- unlist(str_split(text, "[\\.!?]+"))
chunks <- str_trim(chunks, "both")
chunks <- chunks[nchar(chunks) > 0]
return(chunks)
}
}
chunk_text(word, T)
chunk_text(word, T)
chunk_text(word)
word <- "This is certainly easier and more efficient than writing the code yourself. In general using quanteda to generate document-term matrices makes a lot of sense for ingesting most text corpora. In fact, this is what I currently do in all of my research code. One of the particularly useful features of the quanteda package is that it automatically stores document-term matrices as sparse matrix objects, which tends to be enormously more space efficient than using dense matrices.
If you are interested in working with the Stanford CoreNLP and MALLET libraries from R , I have a (beta) R package that wraps these libraries, along with providing a number of utility and document comparison functions. This package is meant to serve as a complement to the quanteda package, and may be a good option if the user is interested in heavy NLP applications in R The package is available on GitHub here: https://github.com/matthewjdenny/SpeedReader. "
chunk_text(word)
chunk_text(word)
chunk_text(word, T)
test <- c('mei', 'bui', 'nilai', 'hancurlah', 'benarkah', 'apatah', 'siapapun', 'jubahku', 'bajumu', 'celananya', 'hantui', 'sampaikan', 'jualan', 'bukumukah', 'miliknyalah', 'kulitkupun', 'berikanku', 'sakitimu', 'beriannya', 'kasihilah', 'dibuang', 'kesakitan', 'vokalis', 'teriakanmu', 'beradu', 'berambut', 'bersuara', 'berdaerah', 'belajar', 'bekerja', 'beternak', 'terasing', 'teraup', 'tergerak', 'terpuruk', 'teterbang', 'melipat', 'meringkas', 'mewarnai', 'meyakinkan', 'membangun', 'memfitnah', 'memvonis', 'memperbarui', 'mempel', 'mempelajari', 'meminum', 'memukul', 'mencinta', 'menduakan', 'menjauh', 'menziarah', 'menuklir', 'menangkap', 'menggila', 'menghajar', 'mengqasar', 'mengudara', 'mengupas', 'menyuarakan', 'mempopulerkan', 'pewarna', 'peyoga', 'peradilan', 'perumahan', 'permuka', 'perdaerah', 'pembangun', 'pemfitnah', 'pemvonis', 'peminum', 'pemukul', 'pencinta', 'pendahulu', 'penjarah', 'penziarah', 'penasihat', 'penangkap', 'penggila', 'penghajar', 'pengqasar', 'pengudara', 'pengupas', 'penyuara', 'pelajar', 'pelabuhan', 'perserong', 'petarung', 'terpercaya', 'pekerja', 'peserta', 'mempengaruhi', 'mengkritik', 'bersekolah', 'bertahan', 'mencapai', 'dimulai', 'petani', 'terabai', 'mensyaratkan', 'mensyukuri', 'mengebom', 'mempromosikan', 'memproteksi', 'memprediksi', 'pengkajian', 'pengebom', 'bersembunyi', 'bersembunyilah', 'pelanggan', 'pelaku', 'pelangganmukah', 'pelakunyalah', 'perbaikan', 'kebaikannya', 'bisikan', 'menerangi', 'berimanlah', 'memuaskan', 'berpelanggan', 'bermakanan')
test
system.time(test)
stemmer <- stemmer_cs$new()
system.time(sapply(test, stemmer$stem, USE.NAMES = F))
system.time(sapply(test, stemmer$stem, USE.NAMES = F))
system.time(sapply(test, stemmer$stem, USE.NAMES = F))
output_evaluation <- readRDS("D:/Rumah/skripsilah-sebelum-diskripsikan/_algoritma/kStemInd/output_evaluation.rds")
View(output_evaluation)
library(profvis)
library(kstemind)
library(data.table)
cdt <- readRDS("ind_news_2012_10K_sentences.tokenized.rds")
kamus <- kstemind_load_data("kamus_sastrawi")
scdt <- cdt
cdt_table_in_list <- lapply(scdt, as.data.table)
cdt_table <- rbindlist(cdt_table_in_list)
cdt_unique <- unique(cdt_table)
cdtu.dt <- data.table(word = cdt_unique, root = character(22772))
cdtu.dt
stopwords <- as.data.table(read.table("data-raw/stopwords.txt", quote="\"", comment.char=""))
stopwords
ns.cdtu.dt <- cdtu.dt[!cdtu.dt$word.V1 %in% stopwords$V1]
len <- ns.cdtu.dt[, .N]
for(i in 1:len) {
if(kamus$has_key(ns.cdtu.dt[i,word.V1]))
set(ns.cdtu.dt, i, 2L, ns.cdtu.dt[i,word.V1])
}
library(stringr)
wns.cdtu.dt <- ns.cdtu.dt[!str_detect(ns.cdtu.dt$word.V1, "[0-9]")]
wns.cdtu.dt
# ############### How to compare output
library(stringdist)
library(kstemind)
library(stringr)
# ############### How to compare output
library(stringdist)
library(kstemind)
library(stringr)
library(readr)
input_text_uji <- read_csv("others/input-text-uji.txt", col_names = FALSE)
output_lucene_porter_tala <- read_csv("others/output-lucene-porter-tala.txt", col_names = FALSE)
output_nondeterministik_inanlp <- read_csv("others/output-nondeterministik-inanlp.txt", col_names = FALSE)
output_nazief_php <- read_csv("others/output-nazief-php.txt", col_names = FALSE)
output_sastrawi_py <- read_csv("others/output-sastrawi-py.txt", col_names = FALSE)
calculate_ssm <- function(output_stem_a, output_stem_b, original_words = input_text_uji$X1) {
len_ <- sapply(original_words, str_length, USE.NAMES = F)
dist_ <- stringdist(output_stem_a, output_stem_b)
rel_mhd_ <- sapply(1:1000, function(x){
return(dist_[x]/len_[x])
}, USE.NAMES = F)
ssm_ <- abs(100*((sum(rel_mhd_)/1000)-1))
message("ssm : ", ssm_)
df_ <- cbind(original_words, output_stem_a, output_stem_b)
diff_ <- df_[which(df_[,2] != df_[,3]),]
invisible(list(ssm=ssm_, diff=diff_))
}
stp <- stemmer_tala_porter$new()
snd <- stemmer_nondeterministic$new()
sna <- stemmer_nazief_andriani$new()
ssa <- stemmer_sastrawi$new()
output_kstemind_tala_porter <- sapply(input_text_uji$X1, stp$stem, USE.NAMES = F)
output_kstemind_nondeterministic <- sapply(input_text_uji$X1, snd$stem, USE.NAMES = F)
output_kstemind_nazief_andriani <- sapply(input_text_uji$X1, sna$stem, USE.NAMES = F)
output_kstemind_sastrawi <- sapply(input_text_uji$X1, ssa$stem, USE.NAMES = F)
ssm <- list(
tala_porter = calculate_ssm(output_kstemind_tala_porter, output_lucene_porter_tala$X1),
nondeterministic = calculate_ssm(output_kstemind_nondeterministic, output_nondeterministik_inanlp$X1),
nazief_andriani = calculate_ssm(output_kstemind_nazief_andriani, output_nazief_php$X1),
sastrawi = calculate_ssm(output_kstemind_sastrawi, output_sastrawi_py$X1)
)
write.csv(output_kstemind_nazief_andriani, "output_kstemind_nazief_andriani.csv")
write.csv(output_kstemind_nondeterministic, "output_kstemind_nondeterministic.csv")
write.csv(output_kstemind_sastrawi, "output_kstemind_sastrawi.csv")
write.csv(output_kstemind_tala_porter, "output_kstemind_tala_porter.csv")
ssm
write.table(output_kstemind_nazief_andriani, "output_kstemind_nazief_andriani.txt")
output_kstemind_nazief_andriani
write.table(output_kstemind_nazief_andriani, "others/output_kstemind_nazief_andriani.txt", row.names = F)
write.table(output_kstemind_nazief_andriani, "others/output_kstemind_nazief_andriani.txt", row.names = F, col.names = NA)
write.table(output_kstemind_nazief_andriani, "others/output_kstemind_nazief_andriani.txt", row.names = F, quote = F)
write.table(output_kstemind_nazief_andriani, "others/output_kstemind_nazief_andriani.txt", row.names = F, quote = F)
write.table(output_kstemind_nondeterministic, "others/output_kstemind_nondeterministic.csv", quote = F)
write.table(output_kstemind_sastrawi, "others/output_kstemind_sastrawi.csv", quote = F)
write.table(output_kstemind_tala_porter, "others/output_kstemind_tala_porter.csv", quote = F)
write.table(output_kstemind_nazief_andriani, "others/output_kstemind_nazief_andriani.txt", row.names = F, quote = F)
write.table(output_kstemind_nondeterministic, "others/output_kstemind_nondeterministic.txt", quote = F)
write.table(output_kstemind_sastrawi, "others/output_kstemind_sastrawi.txt", quote = F)
write.table(output_kstemind_tala_porter, "others/output_kstemind_tala_porter.txt", quote = F)
write.table(output_kstemind_nazief_andriani, "others/output_kstemind_nazief_andriani.txt", row.names = F, quote = F)
write.table(output_kstemind_nondeterministic, "others/output_kstemind_nondeterministic.csv", row.names = F, quote = F)
write.table(output_kstemind_sastrawi, "others/output_kstemind_sastrawi.csv", row.names = F, quote = F)
write.table(output_kstemind_tala_porter, "others/output_kstemind_tala_porter.csv", row.names = F, quote = F)
write.table(output_kstemind_nazief_andriani, "others/output_kstemind_nazief_andriani.txt", row.names = F, quote = F)
write.table(output_kstemind_nondeterministic, "others/output_kstemind_nondeterministic.txt", row.names = F, quote = F)
write.table(output_kstemind_sastrawi, "others/output_kstemind_sastrawi.txt", row.names = F, quote = F)
write.table(output_kstemind_tala_porter, "others/output_kstemind_tala_porter.txt", row.names = F, quote = F)
ssm <- list(
tala_porter = calculate_ssm(output_kstemind_tala_porter, output_lucene_porter_tala$X1),
nondeterministic = calculate_ssm(output_kstemind_nondeterministic, output_nondeterministik_inanlp$X1),
nazief_andriani = calculate_ssm(output_kstemind_nazief_andriani, output_nazief_php$X1),
sastrawi = calculate_ssm(output_kstemind_sastrawi, output_sastrawi_py$X1)
)
library(stringr)
max(10, 11)
zzz <- pairlist(output_kstemind_tala_porter, output_lucene_porter_tala$X1)
zzz
output_stem_a <- output_kstemind_tala_porter
output_stem_b <- output_lucene_porter_tala$X1
list_len_ <- list(
len_a = sapply(output_stem_a, str_length, USE.NAMES = F),
len_b = sapply(output_stem_b, str_length, USE.NAMES = F)
)
max(list_len_)
zzz <- vector(, length = 1000)
for(i in 1:1000)
?
}}
zzz <- vector(mode = "integer", length = 1000)
L <- list(
len_a = sapply(output_stem_a, str_length, USE.NAMES = F),
len_b = sapply(output_stem_b, str_length, USE.NAMES = F)
)
len_ <- sapply(1:en_, function(x){
return(max(L$len_a[x], L$len_b[x]))
}, USE.NAMES = F)
en_ <- length(output_stem_a)
len_ <- sapply(1:en_, function(x){
return(max(L$len_a[x], L$len_b[x]))
}, USE.NAMES = F)
# ############### How to compare output
library(stringdist)
library(kstemind)
library(stringr)
library(readr)
input_text_uji <- read_csv("others/input-text-uji.txt", col_names = FALSE)
output_lucene_porter_tala <- read_csv("others/output-lucene-porter-tala.txt", col_names = FALSE)
output_nondeterministik_inanlp <- read_csv("others/output-nondeterministik-inanlp.txt", col_names = FALSE)
output_nazief_php <- read_csv("others/output-nazief-php.txt", col_names = FALSE)
output_sastrawi_py <- read_csv("others/output-sastrawi-py.txt", col_names = FALSE)
calculate_ssm <- function(output_stem_a, output_stem_b, original_words = input_text_uji$X1) {
en_ <- length(output_stem_a)
L <- list(
len_a = sapply(output_stem_a, str_length, USE.NAMES = F),
len_b = sapply(output_stem_b, str_length, USE.NAMES = F)
)
len_ <- sapply(1:en_, function(x){
return(max(L$len_a[x], L$len_b[x]))
}, USE.NAMES = F)
dist_ <- stringdist(output_stem_a, output_stem_b)
rel_mhd_ <- sapply(1:en_, function(x){
return(dist_[x]/len_[x])
}, USE.NAMES = F)
ssm_ <- abs(100*((sum(rel_mhd_)/en_)-1))
message("ssm : ", ssm_)
df_ <- cbind(original_words, output_stem_a, output_stem_b)
diff_ <- df_[which(df_[,2] != df_[,3]),]
invisible(list(ssm=ssm_, diff=diff_))
}
stp <- stemmer_tala_porter$new()
snd <- stemmer_nondeterministic$new()
sna <- stemmer_nazief_andriani$new()
ssa <- stemmer_sastrawi$new()
output_kstemind_tala_porter <- sapply(input_text_uji$X1, stp$stem, USE.NAMES = F)
output_kstemind_nondeterministic <- sapply(input_text_uji$X1, snd$stem, USE.NAMES = F)
output_kstemind_nazief_andriani <- sapply(input_text_uji$X1, sna$stem, USE.NAMES = F)
output_kstemind_sastrawi <- sapply(input_text_uji$X1, ssa$stem, USE.NAMES = F)
ssm <- list(
tala_porter = calculate_ssm(output_kstemind_tala_porter, output_lucene_porter_tala$X1),
nondeterministic = calculate_ssm(output_kstemind_nondeterministic, output_nondeterministik_inanlp$X1),
nazief_andriani = calculate_ssm(output_kstemind_nazief_andriani, output_nazief_php$X1),
sastrawi = calculate_ssm(output_kstemind_sastrawi, output_sastrawi_py$X1)
)
calculate_ssm <- function(output_stem_a, output_stem_b, original_words = input_text_uji$X1) {
en_ <- length(output_stem_a)
L <- list(
len_a = sapply(output_stem_a, str_length, USE.NAMES = F),
len_b = sapply(output_stem_b, str_length, USE.NAMES = F)
)
len_ <- sapply(1:en_, function(x){
return(max(L$len_a[x], L$len_b[x]))
}, USE.NAMES = F)
dist_ <- stringdist(output_stem_a, output_stem_b)
rel_mhd_ <- sapply(1:en_, function(x){
return(dist_[x]/len_[x])
}, USE.NAMES = F)
ssm_ <- abs(100*((sum(rel_mhd_)/en_)-1))
print((sum(rel_mhd_)/en_))
message("ssm : ", ssm_)
df_ <- cbind(original_words, output_stem_a, output_stem_b)
diff_ <- df_[which(df_[,2] != df_[,3]),]
invisible(list(ssm=ssm_, diff=diff_))
}
ssm <- list(
tala_porter = calculate_ssm(output_kstemind_tala_porter, output_lucene_porter_tala$X1),
nondeterministic = calculate_ssm(output_kstemind_nondeterministic, output_nondeterministik_inanlp$X1),
nazief_andriani = calculate_ssm(output_kstemind_nazief_andriani, output_nazief_php$X1),
sastrawi = calculate_ssm(output_kstemind_sastrawi, output_sastrawi_py$X1)
)
calculate_ssm <- function(output_stem_a, output_stem_b, original_words = input_text_uji$X1) {
en_ <- length(output_stem_a)
L <- list(
len_a = sapply(output_stem_a, str_length, USE.NAMES = F),
len_b = sapply(output_stem_b, str_length, USE.NAMES = F)
)
len_ <- sapply(1:en_, function(x){
return(max(L$len_a[x], L$len_b[x]))
}, USE.NAMES = F)
dist_ <- stringdist(output_stem_a, output_stem_b)
rel_mhd_ <- sapply(1:en_, function(x){
return(dist_[x]/len_[x])
}, USE.NAMES = F)
ssm_ <- abs(100*((sum(rel_mhd_)/en_)-1))
print(1/(sum(rel_mhd_)/en_))
message("ssm : ", ssm_)
df_ <- cbind(original_words, output_stem_a, output_stem_b)
diff_ <- df_[which(df_[,2] != df_[,3]),]
invisible(list(ssm=ssm_, diff=diff_))
}
ssm <- list(
tala_porter = calculate_ssm(output_kstemind_tala_porter, output_lucene_porter_tala$X1),
nondeterministic = calculate_ssm(output_kstemind_nondeterministic, output_nondeterministik_inanlp$X1),
nazief_andriani = calculate_ssm(output_kstemind_nazief_andriani, output_nazief_php$X1),
sastrawi = calculate_ssm(output_kstemind_sastrawi, output_sastrawi_py$X1)
)
calculate_ssm <- function(output_stem_a, output_stem_b, original_words = input_text_uji$X1) {
en_ <- length(output_stem_a)
L <- list(
len_a = sapply(output_stem_a, str_length, USE.NAMES = F),
len_b = sapply(output_stem_b, str_length, USE.NAMES = F)
)
len_ <- sapply(1:en_, function(x){
return(max(L$len_a[x], L$len_b[x]))
}, USE.NAMES = F)
dist_ <- stringdist(output_stem_a, output_stem_b, method = "hamming")
rel_mhd_ <- sapply(1:en_, function(x){
return(dist_[x]/len_[x])
}, USE.NAMES = F)
ssm_ <- abs(100*((sum(rel_mhd_)/en_)-1))
message("ssm : ", ssm_)
df_ <- cbind(original_words, output_stem_a, output_stem_b)
diff_ <- df_[which(df_[,2] != df_[,3]),]
invisible(list(ssm=ssm_, diff=diff_))
}
ssm <- list(
tala_porter = calculate_ssm(output_kstemind_tala_porter, output_lucene_porter_tala$X1),
nondeterministic = calculate_ssm(output_kstemind_nondeterministic, output_nondeterministik_inanlp$X1),
nazief_andriani = calculate_ssm(output_kstemind_nazief_andriani, output_nazief_php$X1),
sastrawi = calculate_ssm(output_kstemind_sastrawi, output_sastrawi_py$X1)
)
stringdist(output_kstemind_nazief_andriani, output_kstemind_nondeterministic, method = "hamming")
stringdist(output_kstemind_nazief_andriani, output_kstemind_nondeterministic, method="hamming")
stringdist(output_kstemind_nazief_andriani, output_kstemind_nondeterministic, method="osa")
stringdist(output_kstemind_nazief_andriani, output_kstemind_nondeterministic, method="lv")
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="lv")
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="lv")
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="osa")
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="dl")
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="hamming")
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="js")
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="jw")
seq_dist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="jw")
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="jw")
seq_dist(c("try", 'tried', "trying"), c("tri", "tri", "tri"))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="js")
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="cosine")
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="qgram")
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="lcs")
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="osa")
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="osa", weight = c(d = 1, i = 2, s = 1, t = 1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method="osa", weight = c(d = 1, i = 0, s = 1, t = 1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(d = 1, i = 0, s = 1, t = 1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(1, 0, 1, 1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(1, 1, 1, 0.5))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(1, 1, 1, 0))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(1, 1, 1, 0.5))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(1, 1, 1, 2))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(0.1, 0.1, 0.1, 0.1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(0.1, 0.1, 0.1, 0.2))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(0.1, 0.1, 0.1, 0.1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(0.1, 0.1, 0.2, 0.1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(0.1, 0.1, 0.1, 0.1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(0.1, 0.2, 0.1, 0.1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(0.2, 0.1, 0.1, 0.1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), weight = c(0.1, 0.2, 0.1, 0.1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method='dl'. weight = c(0.1, 0.2, 0.1, 0.1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method='dl', weight = c(0.1, 0.2, 0.1, 0.1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method='dl', weight = c(0.1, 0.1, 0.1, 0.1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method='dl', weight = c(0.1, 0.1, 0.2, 0.1))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method='dl', weight = c(0.1, 0.1, 0.2, 0.0))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method='dl', weight = c(0.1, 0.1, 0.2, 0.001))
stringdist(c("try", 'tried', "trying"), c("tri", "tri", "tri"), method='dl', weight = c(0.1, 0.1, 0.2, 0.1))
stringdist(c("try", 'tried', "trying", "tir"), c("tri", "tri", "tri", "tri"), method='dl', weight = c(0.1, 0.1, 0.2, 0.1))
stringdist(c("try", 'tried', "trying", "tiry"), c("tri", "tri", "tri", "tri"), method='dl', weight = c(0.1, 0.1, 0.2, 0.1))
stringdist(c("try", 'tried', "tryi"), c("tri", "tri", "tri"))
stringdist(c("try", 'tried', "try"), c("tri", "tri", "tri"))
stringdist(c("try", 'tried', "tryi"), c("tri", "tri", "tri"))
str_sub("abc", end = 2)
calculate_ssm <- function(output_stem_a, output_stem_b, original_words = input_text_uji$X1) {
en_ <- length(output_stem_a)
L <- list(
len_a = sapply(output_stem_a, str_length, USE.NAMES = F),
len_b = sapply(output_stem_b, str_length, USE.NAMES = F)
)
maxlen_ <- sapply(1:en_, function(x){
return(max(L$len_a[x], L$len_b[x]))
}, USE.NAMES = F)
minlen_ <- sapply(1:en_, function(x){
return(min(L$len_a[x], L$len_b[x]))
}, USE.NAMES = F)
# dist_ <- stringdist(output_stem_a, output_stem_b, method = "hamming")
dist_ <- sapply(1:en_, function(x) {
this_stem_a <- str_sub(output_stem_a[x], end = minlen_[x])
this_stem_b <- str_sub(output_stem_b[x], end = minlen_[x])
this_dist <- stringdist(this_stem_a, this_stem_b, method = "hamming")
return(this_dist + (maxlen_[x]-minlen_[x]))
}, USE.NAMES = F)
rel_mhd_ <- sapply(1:en_, function(x){
return(dist_[x]/maxlen_[x])
}, USE.NAMES = F)
ssm_ <- abs(100*((sum(rel_mhd_)/en_)-1))
message("ssm : ", ssm_)
df_ <- cbind(original_words, output_stem_a, output_stem_b)
diff_ <- df_[which(df_[,2] != df_[,3]),]
invisible(list(ssm=ssm_, diff=diff_))
}
ssm <- list(
tala_porter = calculate_ssm(output_kstemind_tala_porter, output_lucene_porter_tala$X1),
nondeterministic = calculate_ssm(output_kstemind_nondeterministic, output_nondeterministik_inanlp$X1),
nazief_andriani = calculate_ssm(output_kstemind_nazief_andriani, output_nazief_php$X1),
sastrawi = calculate_ssm(output_kstemind_sastrawi, output_sastrawi_py$X1)
)
roxygen2::roxygenise()
roxygen2::roxygenise()
roxygen2::roxygenise()
library(kstemind)
library(kstemind)
