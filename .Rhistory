tokenize_indonesian(cdd[[378]])
cdd[[378]]
tokenize_indonesian(cdd[[378]])
text
text <- str_to_lower(text)
text <- str_replace_all(text, "[^A-Za-z0-9 -]", " ")
text <- str_replace_all(text, "\\W[-]+\\W", " ")
text <- str_split(text, "\\s+")[[1]]
text
text[text != ""]
dataset_accuration <- read_excel("inputmanual_sample.ns.cdtu.dt.xlsx", sheet = "hasil")
##### Empirical Evaluation (EE)
test_EE <- function(STEM_OBJ, dataset = dataset_accuration) {
stemmer <- STEM_OBJ
message("   stemming in progress")
hasil_stemmer <- pbsapply(dataset$word, stemmer$stem_word, USE.NAMES = FALSE)
ee_ <- length(hasil_stemmer[dataset$manual_stem == hasil_stemmer]) / length(hasil_stemmer)
cat("  nilai EE : ", ee_, "\n")
invisible(list(
ee = ee_
# stem_word = hasil_stemmer
)
)
}
length(dataset_accuration$word)
EE <- c(
test_EE(stemmer_nazief_andriani$new())$ee,
test_EE(stemmer_cs$new())$ee,
test_EE(stemmer_ecs$new())$ee,
test_EE(stemmer_incremental$new())$ee,
test_EE(stemmer_nondeterministic$new())$ee,
test_EE(stemmer_tala_porter$new())$ee,
test_EE(stemmer_mecs$new())$ee,
test_EE(stemmer_sastrawi$new())$ee
)
EE_output <- data.frame(stemmer = levels(mb$expr), EE = EE)
EE_output
library(readxl)
library(kstemind)
library(microbenchmark)
library(pbapply)
library(stringdist)
library(readr)
##### Dataset in use (Data)
# sumber : http://wortschatz.uni-leipzig.de/en/download
# link didownload : http://pcai056.informatik.uni-leipzig.de/downloads/corpora/ind_news_2012_10K.tar.gz
dataset_accuration <- read_excel("inputmanual_sample.ns.cdtu.dt.xlsx", sheet = "hasil")
ind_news_2012_10K_sentences <- read_csv("New folder/ind_news_2012_10K-sentences.csv")
dataset <- ind_news_2012_10K_sentences
##### chunk & tokenize sumber data
n <- 10
nr <- nrow(dataset)
chunk_dataset <- split(dataset, rep(1:ceiling(nr/n), each=n, length.out=nr))
cdd <- lapply(chunk_dataset, function(text){paste0(text$sentences, collapse = " ") })
cdt <- lapply(cdd, tokenize_indonesian)
tokenize_indonesian(cdd[[378]])
##### summary c&t sumber data
length(cdt)
mean(unlist(lapply(cdt, length)))
sum(unlist(lapply(cdt, length)))
EE_output
##### Runtime Benchmark
run_stem_words <- function(STEM_OBJ, tokenized_dataset = cdt) {
stemmer <- STEM_OBJ
message("   stemming in progress")
stem_list_ <- pblapply(tokenized_dataset, function(x) {
sapply(x, stemmer$stem, USE.NAMES = FALSE)
})
invisible(stem_list_)
}
(mb <- microbenchmark(
nazief = run_stem_words(stemmer_nazief_andriani$new()),
cs = run_stem_words(stemmer_cs$new()),
ecs = run_stem_words(stemmer_ecs$new()),
incremental = run_stem_words(stemmer_incremental$new()),
nondeterministik = run_stem_words(stemmer_nondeterministic$new()),
tala = run_stem_words(stemmer_tala_porter$new()),
mecs = run_stem_words(stemmer_mecs$new()),
sastrawi = run_stem_words(stemmer_sastrawi$new()),
times = 1L
))
cdt[[370]]
cdt[[371]]
cdt[[372]]
cdt[[373]]
cdt[[374]]
cdt[[375]]
cdt[[376]]
cdt[[377]]
cdt[[378]]
cdt[[379]]
cdt[[380]]
run_stem_words(stemmer_ecs$new(), cdt[370:380])
##### Runtime Benchmark
run_stem_words <- function(STEM_OBJ, tokenized_dataset = cdt) {
stemmer <- STEM_OBJ
message("   stemming in progress")
stem_list_ <- pblapply(tokenized_dataset, function(x) {
cat(x)
sapply(x, stemmer$stem, USE.NAMES = FALSE)
})
invisible(stem_list_)
}
##### Runtime Benchmark
run_stem_words <- function(STEM_OBJ, tokenized_dataset = cdt) {
stemmer <- STEM_OBJ
message("   stemming in progress")
stem_list_ <- lapply(tokenized_dataset, function(x) {
cat(x)
sapply(x, stemmer$stem, USE.NAMES = FALSE)
})
invisible(stem_list_)
}
run_stem_words(stemmer_ecs$new(), cdt[370:380])
run_stem_words(stemmer_ecs$new(), cdt[378])
cdt[378]
sapply(x, function(x) {print(x); stemmer$stem}, USE.NAMES = FALSE)
sapply(x, function(x) {print(x); stemmer$stem(x)}, USE.NAMES = FALSE)
sapply(cdt[[378]], function(a) {print(a); stemmer$stem(a)}, USE.NAMES = FALSE)
sapply(cdt[[378]], function(a) {print(a); s <- stemmer_ecs$new(); s$stem(a)}, USE.NAMES = FALSE)
s <- stemmer_ecs$new()
s$stem("sean")
s <- stemmer_ecs$new()
s <- stemmer_ecs$new()
s$stem("sean")
s <- stemmer_ecs$new()
s <- stemmer_ecs$new()
s$stem("sean")
s <- stemmer_ecs$new()
s$stem("sean")
##### Runtime Benchmark
run_stem_words <- function(STEM_OBJ, tokenized_dataset = cdt) {
stemmer <- STEM_OBJ
message("   stemming in progress")
stem_list_ <- pblapply(tokenized_dataset, function(x) {
sapply(x, stemmer$stem, USE.NAMES = FALSE)
})
invisible(stem_list_)
}
(mb <- microbenchmark(
nazief = run_stem_words(stemmer_nazief_andriani$new()),
cs = run_stem_words(stemmer_cs$new()),
ecs = run_stem_words(stemmer_ecs$new()),
incremental = run_stem_words(stemmer_incremental$new()),
nondeterministik = run_stem_words(stemmer_nondeterministic$new()),
tala = run_stem_words(stemmer_tala_porter$new()),
mecs = run_stem_words(stemmer_mecs$new()),
sastrawi = run_stem_words(stemmer_sastrawi$new()),
times = 1L
))
##### Test stemmer strength (MCW, ICF, WCF, Average CR)
test_strength <- function(STEM_OBJ, tokenized_dataset) {
# N : jumlah unique words before stemmer
# S : jumlah unique words after stemmer
stemmer <- STEM_OBJ
message("   stemming in progress")
stem_list_ <- pblapply(tokenized_dataset, function(x) {
sapply(x, stemmer$stem, USE.NAMES = FALSE)
})
arr_after_stem <- unlist(stem_list_, use.names = FALSE)
arr_before_stem <- unlist(tokenized_dataset, use.names = FALSE)
arr_no_changes_stem <- arr_before_stem[arr_before_stem==arr_after_stem]
dist_df <- data.table(
before = arr_before_stem,
after = arr_after_stem,
distance = NA
)
u_dist_df <- unique(dist_df)
set(u_dist_df, i=NULL, 3L, stringdist(u_dist_df[,before], u_dist_df[,after]))
S <- length(unique(arr_after_stem))
N <- length(unique(arr_before_stem))
C <- length(unique(arr_no_changes_stem))
message("testing a stemmer")
mwc_ <- N/S
icf_ <- (N-S)/N
wcf_ <- (N-C)/N
arc_ <- u_dist_df[, mean(distance)]
cat("  nilai MWC : ", mwc_, "\n")
cat("  nilai ICF : ", icf_, "\n")
cat("  nilai WCF : ", wcf_, "\n")
cat("  nilai ARC : ", arc_, "\n\n")
invisible(list(
mwc = mwc_,
icf = icf_,
wcf = wcf_,
arc = arc_
# arr_after = arr_after_stem,
# arr_before = arr_before_stem
))
}
STRENGTH <- list(
test_strength(stemmer_nazief_andriani$new(), cdt[100:120]),
test_strength(stemmer_cs$new(), cdt[100:120]),
test_strength(stemmer_ecs$new(), cdt[100:120]),
test_strength(stemmer_incremental$new(), cdt[100:120]),
test_strength(stemmer_nondeterministic$new(), cdt[100:120]),
test_strength(stemmer_tala_porter$new(), cdt[100:120]),
test_strength(stemmer_mecs$new(), cdt[100:120]),
test_strength(stemmer_sastrawi$new(), cdt[100:120])
)
STRENGTH_output <- cbind(data.frame(stemmer = levels(mb$expr)), rbindlist(STRENGTH))
#### Show Output Eval (Strength only 20 data)
EE_output
RT_output
RT_output <- mb
RT_output
STRENGTH_output
(mb <- microbenchmark(
nazief = run_stem_words(stemmer_nazief_andriani$new()),
cs = run_stem_words(stemmer_cs$new()),
ecs = run_stem_words(stemmer_ecs$new()),
incremental = run_stem_words(stemmer_incremental$new()),
nondeterministik = run_stem_words(stemmer_nondeterministic$new()),
tala = run_stem_words(stemmer_tala_porter$new()),
mecs = run_stem_words(stemmer_mecs$new()),
sastrawi = run_stem_words(stemmer_sastrawi$new()),
times = 10L
))
tokenize_indonesian('Setiap gerakan pertolongan merupakan nilai pahala ” Siapa yang menolong saudaranya yang lain maka Allah akan menuliskan baginya tujuh kebaikan bagi & setiap langkah yang dilakukannya ” (HR. Thabrani ).
')
text <- '[1] "setiap" "gerakan" "pertolongan" "merupakan" "nilai" "pahala" "siapa" [8] "yang" "menolong" "saudaranya" "yang" "lain" "maka" "allah" [15] "akan" "menuliskan" "baginya" "tujuh" "kebaikan" "bagi" "setiap" [22] "langkah" "yang" "dilakukannya" "hr" "thabrani"
'
text <- 'Setiap gerakan pertolongan merupakan nilai pahala ” Siapa yang menolong saudaranya yang lain maka Allah akan menuliskan baginya tujuh kebaikan bagi & setiap langkah yang dilakukannya ” (HR. Thabrani ).
'
str_to_lower(text)
stopwords <- as.data.table(read.table("data-raw/stopwords.txt", quote="\"", comment.char=""))
stopwords
text
tokenize_indonesian('Setiap gerakan pertolongan merupakan nilai pahala ” Siapa yang menolong saudaranya yang lain maka Allah akan menuliskan baginya tujuh kebaikan bagi & setiap langkah yang dilakukannya ” (HR. Thabrani ).
')
a <- tokenize_indonesian('Setiap gerakan pertolongan merupakan nilai pahala ” Siapa yang menolong saudaranya yang lain maka Allah akan menuliskan baginya tujuh kebaikan bagi & setiap langkah yang dilakukannya ” (HR. Thabrani ).
')
a
a[!a %in% stopwords$V1]
install.packages("plumber")
pr <- plumber::plumb("others/api_kstemind.R")
pr$run()
a <- tokenize_indonesian('Setiap gerakan pertolongan merupakan nilai pahala ” Siapa yang menolong saudaranya yang lain maka Allah akan menuliskan baginya tujuh kebaikan bagi & setiap langkah yang dilakukannya ” (HR. Thabrani ).
')
#' Global Vars
stemmer <- list(
stemmer_nazief_andriani$new()),
stemmer_cs$new()),
stemmer_ecs$new()),
stemmer_incremental$new()),
stemmer_nondeterministic$new()),
stemmer_tala_porter$new()),
stemmer_mecs$new()),
stemmer_sastrawi$new())
#' Global Vars
stemmer <- list(
stemmer_nazief_andriani$new(),
stemmer_cs$new(),
stemmer_ecs$new(),
stemmer_incremental$new(),
stemmer_nondeterministic$new(),
stemmer_tala_porter$new(),
stemmer_mecs$new(),
stemmer_sastrawi$new()
)
a
sapply(tokenize_indonesian(msg), stemmer[1]$stem, USE.NAMES = F)
sapply(tokenize_indonesian(msg), stemmer[[1]]$stem, USE.NAMES = F)
msg <- 'Setiap gerakan pertolongan merupakan nilai pahala ” Siapa yang menolong saudaranya yang lain maka Allah akan menuliskan baginya tujuh kebaikan bagi & setiap langkah yang dilakukannya ” (HR. Thabrani ).
'
sapply(tokenize_indonesian(msg), stemmer[[1]]$stem, USE.NAMES = F)
paste0(sapply(tokenize_indonesian(msg), stemmer[[1]]$stem, USE.NAMES = F), collapse = " ")
pr <- plumber::plumb("others/api_kstemind.R")
pr$run()
length(unique(unlist(lapply(cdt, length))))
unique(unlist(lapply(cdt, length)))
unlist(lapply(cdt, length))
length(unique(unlist(cdt)))
library(reprex)
install.packages(reprex)
install.packages("reprex")
reprex(head(stopwords))
reprex(head(stopwords))
library(reprex)
reprex(head(stopwords))
reprex()
reprex()
kamus <- read.table("data-raw/kamus_sastrawi.txt", quote="\"", comment.char="")
reprex()
reprex()
reprex()
reprex()
reprex()
reprex()
reprex()
mb
plot(mb)
autoplot(mb)
library(microbenchmark)
autoplot(mb)
microbenchmark::autoplot.microbenchmark(mb)
boxplot(mb)
library(readr)
input_text_uji <- read_csv("others/input-text-uji.txt",
col_names = FALSE)
View(input_text_uji)
library(readr)
output_lucene_porter_tala <- read_csv("others/output-lucene-porter-tala.txt",
col_names = FALSE)
View(output_lucene_porter_tala)
library(readr)
output_nazief_php <- read_csv("others/output-nazief-php.txt")
View(output_nazief_php)
library(readr)
output_nondeterministik_inanlp <- read_csv("others/output-nondeterministik-inanlp.txt",
col_names = FALSE)
library(readr)
output_nazief_php <- read_csv("others/output-nazief-php.txt",
col_names = FALSE)
# ############### How to compare output
library(stringdist)
c <- stringdist()
library(kstemind)
stp <- stemmer_tala_porter$new()
output_kstemind_porter_tala <- sapply(input_text_uji$X1, stp$stem, USE.NAMES = F)
c <- stringdist(output_kstemind_porter_tala, output_lucene_porter_tala$X1)
c
mean(c)
max(c)
library(stringr)
len <- sapply(output_kstemind_porter_tala, length, USE.NAMES = F)
len
len <- sapply(output_kstemind_porter_tala, str_length, USE.NAMES = F)
len
dist_lucene <- stringdist(output_kstemind_porter_tala, output_lucene_porter_tala$X1)
b <- sapply(1:1000, function(x){
return(dist_lucene[x]/len[x])
}, USE.NAMES = F)
b
sum(b)
100*(sum(b)/1000)-1
sum(b)/1000
100*((sum(b)/1000)-1)
100 * ((0.25 + 0.0345 + 0)/3 ) - 1)
100 * ((0.25 + 0.0345 + 0)/3 ) - 1)
100 * ((0.25 + 0.0345 + 0)/3 ) - 1
100 * (((0.25 + 0.0345 + 0)/3 ) - 1)
100 * (((0.25 + 0.0345 + 0)/3 ) )
100 * (((0.25 + 0.0345 + 0)/3 ) - 1)
abs(100 * (((0.25 + 0.0345 + 0)/3 ) - 1)))
abs(100 * (((0.25 + 0.0345 + 0)/3 ) - 1))
abs(100*((sum(b)/1000)-1))
calculate_ssm <- function(output_stem_a, output_stem_b, original_words) {
len_ <- sapply(original_words, str_length, USE.NAMES = F)
dist_ <- stringdist(output_stem_a, output_stem_b)
rel_mhd_ <- sapply(1:1000, function(x){
return(dist_[x]/len[x])
}, USE.NAMES = F)
return( abs(100*((sum(rel_mhd_)/1000)-1)) )
}
input_text_uji <- read_csv("others/input-text-uji.txt", col_names = FALSE)
output_lucene_porter_tala <- read_csv("others/output-lucene-porter-tala.txt", col_names = FALSE)
output_nondeterministik_inanlp <- read_csv("others/output-nondeterministik-inanlp.txt", col_names = FALSE)
output_nazief_php <- read_csv("others/output-nazief-php.txt", col_names = FALSE)
output_sastrawi_py <- read_csv("others/output-sastrawi-py.txt", col_names = FALSE)
stp <- stemmer_tala_porter$new()
snd <- stemmer_nondeterministic$new()
sna <- stemmer_nazief_andriani$new()
ssa <- stemmer_sastrawi$new()
output_kstemind_tala_porter <- sapply(input_text_uji$X1, stp$stem, USE.NAMES = F)
output_kstemind_nondeterministic <- sapply(input_text_uji$X1, snd$stem, USE.NAMES = F)
calculate_ssm <- function(output_stem_a, output_stem_b, original_words = input_text_uji$X1) {
len_ <- sapply(original_words, str_length, USE.NAMES = F)
dist_ <- stringdist(output_stem_a, output_stem_b)
rel_mhd_ <- sapply(1:1000, function(x){
return(dist_[x]/len[x])
}, USE.NAMES = F)
return( abs(100*((sum(rel_mhd_)/1000)-1)) )
}
calculate_ssm <- function(output_stem_a, output_stem_b, original_words = input_text_uji$X1) {
len_ <- sapply(original_words, str_length, USE.NAMES = F)
dist_ <- stringdist(output_stem_a, output_stem_b)
rel_mhd_ <- sapply(1:1000, function(x){
return(dist_[x]/len[x])
}, USE.NAMES = F)
ssm_ <- abs(100*((sum(rel_mhd_)/1000)-1))
print("ssm : ", ssm_)
invisible(ssm_)
}
ssm <- list(
tala_porter = calculate_ssm(input_text_uji$X1, output_kstemind_tala_porter),
nondeterministic = calculate_ssm(input_text_uji$X1, output_kstemind_nondeterministic),
nazief_andriani = calculate_ssm(input_text_uji$X1, output_kstemind_nazief_andriani),
sastrawi = calculate_ssm(input_text_uji$X1, output_kstemind_sastrawi)
)
calculate_ssm <- function(output_stem_a, output_stem_b, original_words = input_text_uji$X1) {
len_ <- sapply(original_words, str_length, USE.NAMES = F)
dist_ <- stringdist(output_stem_a, output_stem_b)
rel_mhd_ <- sapply(1:1000, function(x){
return(dist_[x]/len[x])
}, USE.NAMES = F)
ssm_ <- abs(100*((sum(rel_mhd_)/1000)-1))
message("ssm : ", ssm_)
invisible(ssm_)
}
ssm <- list(
tala_porter = calculate_ssm(input_text_uji$X1, output_kstemind_tala_porter),
nondeterministic = calculate_ssm(input_text_uji$X1, output_kstemind_nondeterministic),
nazief_andriani = calculate_ssm(input_text_uji$X1, output_kstemind_nazief_andriani),
sastrawi = calculate_ssm(input_text_uji$X1, output_kstemind_sastrawi)
)
output_nazief_php
length(output_kstemind_nondeterministic)
length(output_kstemind_nondeterministic)
length(output_nondeterministik_inanlp)
length(output_nondeterministik_inanlp$X1)
ssm <- list(
tala_porter = calculate_ssm(output_kstemind_tala_porter, output_lucene_porter_tala$X1),
nondeterministic = calculate_ssm(output_kstemind_nondeterministic, output_nondeterministik_inanlp$X1),
nazief_andriani = calculate_ssm(output_kstemind_nazief_andriani, output_nazief_php$X1),
sastrawi = calculate_ssm(output_kstemind_sastraw, output_sastrawi$X1)
)
calculate_ssm(output_kstemind_nazief_andriani, output_nazief_php$X1)
output_kstemind_nazief_andriani <- sapply(input_text_uji$X1, sna$stem, USE.NAMES = F)
output_kstemind_sastrawi <- sapply(input_text_uji$X1, ssa$stem, USE.NAMES = F)
output_kstemind_nondeterministic <- sapply(input_text_uji$X1, snd$stem, USE.NAMES = F)
output_kstemind_tala_porter <- sapply(input_text_uji$X1, stp$stem, USE.NAMES = F)
ssm <- list(
tala_porter = calculate_ssm(output_kstemind_tala_porter, output_lucene_porter_tala$X1),
nondeterministic = calculate_ssm(output_kstemind_nondeterministic, output_nondeterministik_inanlp$X1),
nazief_andriani = calculate_ssm(output_kstemind_nazief_andriani, output_nazief_php$X1),
sastrawi = calculate_ssm(output_kstemind_sastraw, output_sastrawi$X1)
)
ssm <- list(
tala_porter = calculate_ssm(output_kstemind_tala_porter, output_lucene_porter_tala$X1),
nondeterministic = calculate_ssm(output_kstemind_nondeterministic, output_nondeterministik_inanlp$X1),
nazief_andriani = calculate_ssm(output_kstemind_nazief_andriani, output_nazief_php$X1),
sastrawi = calculate_ssm(output_kstemind_sastrawi, output_sastrawi_py$X1)
)
ssm
library(kstemind)
library(reprex)
sessionInfo()
Sys.info()
R.version
packageName()
packageDescription(kstemind)
packageDescription("kstemind")
install.packages("benchmarkme")
library(benchmarkme)
## Return the machine CPU
cat("Machine:     "); print(get_cpu()$model_name)
## Return number of true cores
cat("Num cores:   "); print(detectCores(logical = FALSE))
## Return number of threads
cat("Num threads: "); print(detectCores(logical = TRUE))
## Return the machine RAM
cat("RAM:         "); print (get_ram()); cat("\n")
reprex()
cat("Machine:     "); print(get_cpu()$model_name)
cat("Num cores:   "); print(detectCores(logical = FALSE))
cat("Num threads: "); print(detectCores(logical = TRUE))
cat("RAM:         "); print (get_ram()); cat("\n")
get_platform_info()
# Computer information
message("Machine:     ", get_cpu()$model_name)
message("RAM:         ", print (get_ram()))
reprex()
devtools::build_win()
devtools::build_win("kstemind")
devtools::build_win(".")
devtools::build_win()
library(kstemind)
# membangun objek stemmer
stemmer <- stemmer_nazief_andriani$new()
# melakukan stemming
stemmer$stem("pertikaian")
source('D:/Rumah/skripsilah-sebelum-diskripsikan/_algoritma/kStemInd/data-raw/visitors.R')
stopwords <- as.data.table(read.table("data-raw/stopwords.txt", quote="\"", comment.char=""))
stopwords
library(data.table)
stopwords <- as.data.table(read.table("data-raw/stopwords.txt", quote="\"", comment.char=""))
stopwords
saveRDS(stopwords, "R/visitors/stopwords.rds")
library(kstemind)
# membangun objek stemmer
stemmer <- stemmer_nazief_andriani$new()
# melakukan stemming pada sebuah kata
stemmer$stem("pertikaian")
# melakukan stemming pada sebuah teks
teks = "Dalam pasal 4 Undang-undang Nomor 53 Tahun 2010 tentang Disiplin PNS, disebutkan bahwa PNS dilarang menggunakan jabatannya untuk memperkaya diri sendiri ataupun golongan."
sapply(tokenize_indonesian(teks), stemmer$stem(), USE.NAMES = F)
sapply(tokenize_indonesian(teks), stemmer$stem, USE.NAMES = F)
cat(sapply(tokenize_indonesian(teks), stemmer$stem, USE.NAMES = F))
# melakukan stemming pada sebuah teks
teks = "Dalam pasal 4 Undang-undang Nomor 53 Tahun 2010 tentang Disiplin PNS, disebutkan bahwa PNS dilarang menggunakan
jabatannya untuk memperkaya diri sendiri ataupun golongan."
# melakukan stemming pada sebuah teks
teks = "Dalam pasal 4 Undang-undang Nomor 53 Tahun 2010 tentang
Disiplin PNS, disebutkan bahwa PNS dilarang menggunakan jabatannya
untuk memperkaya diri sendiri ataupun golongan."
cat(sapply(tokenize_indonesian(teks), stemmer$stem, USE.NAMES = F))
teks
library(reprex)
reprex()
reprex()
# melakukan stemming pada sebuah kata
stemmer$stem("pertikaian")
roxygen2::roxygenize()
roxygen2::roxygenize()
library(kstemind)
tokenize_indonesian(teks)
roxygen2::roxygenize()
library(kstemind)
tokenize_indonesian(teks)
stopwords_removal(tokenize_indonesian(teks))
stopwords_removal(tokenize_indonesian(teks, do_clean = T))
